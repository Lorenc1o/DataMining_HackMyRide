{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lorenc1o/DataMining_HackMyRide/blob/main/sanitize_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8jF-sA3ENEx",
        "outputId": "c69dda63-5431-44ee-f0f5-c6e9d1126e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2426  100  2426    0     0  93307      0 --:--:-- --:--:-- --:--:-- 97040\n",
            "OK\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.41.9).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n",
            "mkdir: cannot create directory ‘main’: File exists\n",
            "2022/12/13 10:59:45.686713 Start gcsfuse/0.41.9 (Go version go1.18.4) for app \"\" using mount point: /content/main\n",
            "2022/12/13 10:59:45.734930 Opening GCS connection...\n",
            "2022/12/13 10:59:47.307817 Mounting file system \"datamining-ulb\"...\n",
            "2022/12/13 10:59:47.310419 File system has been successfully mounted.\n",
            "data\t    Lines_vehiclePositions  ordered_lines  vehiclePositions\n",
            "esri_files  normalized_lines\t    schedule\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jenkspy in /usr/local/lib/python3.8/dist-packages (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from jenkspy) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ckwrap in /usr/local/lib/python3.8/dist-packages (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ckwrap) (1.21.6)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from ckwrap) (0.29.32)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dbscan1d\n",
            "  Downloading dbscan1d-0.1.6-py3-none-any.whl (7.3 kB)\n",
            "Collecting black\n",
            "  Downloading black-22.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from dbscan1d) (1.21.6)\n",
            "Collecting flake8\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from black->dbscan1d) (4.4.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from black->dbscan1d) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.8/dist-packages (from black->dbscan1d) (2.5.4)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.10.3-py3-none-any.whl (29 kB)\n",
            "Collecting pycodestyle<2.11.0,>=2.10.0\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 219 kB/s \n",
            "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pyflakes<3.1.0,>=3.0.0\n",
            "  Downloading pyflakes-3.0.1-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyflakes, pycodestyle, pathspec, mypy-extensions, mccabe, click, flake8, black, dbscan1d\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed black-22.12.0 click-8.1.3 dbscan1d-0.1.6 flake8-6.0.0 mccabe-0.7.0 mypy-extensions-0.4.3 pathspec-0.10.3 pycodestyle-2.10.0 pyflakes-3.0.1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user() # Disable in vm\n",
        "\n",
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse\n",
        "\n",
        "!mkdir main\n",
        "!gcsfuse --implicit-dirs datamining-ulb main\n",
        "\n",
        "!ls /content/main\n",
        "\n",
        "!pip install jenkspy\n",
        "!pip install ckwrap\n",
        "!pip install dbscan1d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime\n",
        "import decimal"
      ],
      "metadata": {
        "id": "kdDfGg2ZGQp-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        " Helper functions & constants\n",
        "'''\n",
        "\n",
        "decimal.getcontext().prec = 3\n",
        "TO_MS = decimal.Decimal(\"1000\")\n",
        "STOP_DISTANCE_THRESHOLD = 5 # In metres\n",
        "AVERAGE_SPEED = decimal.Decimal(\"4.667\") # in metre/second\n",
        "\n",
        "def epoch_ms_to_datetime(epoch_ms: int) -> datetime.datetime:\n",
        "    return datetime.datetime.fromtimestamp(epoch_ms / int(TO_MS))"
      ],
      "metadata": {
        "id": "3pQs_LKBUH9f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract actual stops\n",
        "actual_df = pd.read_csv(\"/content/main/data/actual_stops.csv\")\n",
        "size = actual_df.shape[0]\n",
        "actual_df[\"stop_id\"] = [re.sub(\"\\D\", \"\", x.strip()) for x in actual_df[\"stop_id\"]]\n",
        "\n",
        "actual_df[\"succession\"] = actual_df[\"succession\"].astype(str)\n",
        "actual_df[\"numero_lig\"] = actual_df[\"numero_lig\"].astype(str)\n",
        "actual_df[\"variante\"] = actual_df[\"variante\"].astype(str)\n",
        "actual_stops = set(actual_df[\"stop_id\"])\n",
        "\n",
        "# Extract Line stop sequence\n",
        "extracted_lines = {}\n",
        "\n",
        "delimiters = np.array([\"_\" for _ in range(size)])\n",
        "stops_info = (actual_df[\"numero_lig\"].to_numpy() + delimiters +  actual_df[\"succession\"].to_numpy() + delimiters + actual_df[\"variante\"].to_numpy() + delimiters + actual_df[\"stop_id\"].to_numpy()).tolist()\n",
        "\n",
        "prev_succession = -999999\n",
        "direction = \"\"\n",
        "for stops in stops_info[::-1]:\n",
        "    info = stops.split(\"_\")\n",
        "    if int(prev_succession) < int(info[1]):\n",
        "        direction = info[3]\n",
        "    \n",
        "    data = extracted_lines.setdefault(info[0], {})\n",
        "    \n",
        "    succession_info = data.setdefault(info[3], {})\n",
        "    succession_info[direction] = info[1]\n",
        "    \n",
        "    data[info[3]] = succession_info\n",
        "    extracted_lines[info[0]] = data\n",
        "    \n",
        "    line_direction = data.setdefault(\"direction\", {})\n",
        "    visited_stops = line_direction.setdefault(direction, set())\n",
        "    visited_stops.add(info[3])\n",
        "    \n",
        "    line_direction[direction] = visited_stops\n",
        "    data[\"direction\"] = line_direction\n",
        "    \n",
        "    prev_succession = info[1]\n",
        "\n",
        "'''\n",
        "Pair stops with the succession line, \n",
        " 1. if there's multiple sucession line check whether direction is the same\n",
        " 2. If not, try to find direction id in the direction stops\n",
        " 3. otherwise set sucession to 99999\n",
        "'''\n",
        "\n",
        "lines = []\n",
        "names = set()\n",
        "for file in glob(\"/content/main/ordered_lines/*.csv\"):\n",
        "  name = file.strip().split(\"/\")[4].split(\"_\")[0]\n",
        "  names.add(name)\n",
        "\n",
        "print(names)\n",
        "for file in glob(\"/content/main/Lines_vehiclePositions/*.csv\"):\n",
        "    if \"null\" in file or file in names:\n",
        "      continue\n",
        "\n",
        "    df = pd.read_csv(file)\n",
        "    df[\"lineID\"] = df[\"lineID\"].astype(str)\n",
        "    df[\"directionID\"] = df[\"directionID\"].astype(str)\n",
        "    df[\"pointID\"] = df[\"pointID\"].astype(str).apply(lambda x: x.strip().split(\" \")[0])\n",
        "    \n",
        "    delimiters = np.array([\"_\" for _ in range(df.shape[0])])\n",
        "    stops_infos = (df[\"lineID\"].to_numpy() + delimiters + df[\"directionID\"].to_numpy() + delimiters + df[\"pointID\"].to_numpy() + delimiters + df.index.astype(str).values).tolist()\n",
        "    \n",
        "    succession_arr = []\n",
        "    for stop in stops_infos:\n",
        "        info = stop.split(\"_\")\n",
        "        data = extracted_lines[info[0]]\n",
        "        \n",
        "        succession = 999999\n",
        "        if info[2] not in data:\n",
        "            succession_arr.append(succession)\n",
        "            continue\n",
        "        \n",
        "        succession_info = data[info[2]]\n",
        "        if info[1] not in succession_info:\n",
        "            succession_arr.append(succession)\n",
        "            continue\n",
        "        \n",
        "        succession = succession_info[info[1]]\n",
        "        succession_arr.append(succession)\n",
        "    \n",
        "    df[\"succession\"] = np.array(succession_arr)\n",
        "    \n",
        "    df[\"lineID\"] = df[\"lineID\"].astype(int)\n",
        "    df[\"directionID\"] = df[\"directionID\"].astype(int)\n",
        "    df[\"pointID\"] = df[\"pointID\"].astype(int)\n",
        "    df[\"succession\"] = df[\"succession\"].astype(int)\n",
        "\n",
        "    name = file.strip().split(\"/\")[4].split(\"_\")[0]\n",
        "    df.sort_values([\"directionID\", \"time\",  \"succession\",], ascending=[True, True, True]).to_csv(f\"/content/main/ordered_lines/{name}_ordered.csv\")\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plV2dAvGjIZ",
        "outputId": "56515dfd-55e0-49f0-81f7-28abab662fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Line71', 'Line93', 'Line20', 'Line78', 'Line6', 'Line28', 'Line95', 'Line33', 'Line27', 'Line38', 'Line47', 'Line79', 'Line13', 'Line62', 'Line48', 'Line43', 'Line58', 'Line92', 'Line46', 'Line12', 'Line42', 'Line57', 'Line74', 'Line1', 'Line88', 'Line89', 'Line77', 'Line54', 'Line19', 'Line39', 'Line17', 'Line56', 'Line69', 'Line72', 'Line81', 'Line61', 'Line8', 'Line80', 'Line36', 'Line50', 'Line76', 'Line5', 'Line7', 'Line70', 'Line9', 'Line21', 'Line60', 'Line63', 'Line64', 'Line75', 'Line14', 'Line98', 'Line41', 'Line45', 'Line66', 'Line53', 'Line59', 'Line51', 'Line55', 'Line82', 'Line44', 'Line37', 'Line2', 'Line29', 'Line34', 'Line49', 'Line86', 'Line25', 'Line65', 'Line4', 'Line97', 'Line3', 'Line87', 'Line83'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting 999999 to the right successsion where possible, same bus stop but pointId for different line\n",
        "\n",
        "actual_df = pd.read_csv(\"/content/main/data/actual_stops.csv\")\n",
        "size = actual_df.shape[0]\n",
        "actual_df[\"stop_id\"] = [re.sub(\"\\D\", \"\", x.strip()) for x in actual_df[\"stop_id\"]]\n",
        "actual_df[\"succession\"] = actual_df[\"succession\"].astype(str)\n",
        "actual_df[\"numero_lig\"] = actual_df[\"numero_lig\"].astype(str)\n",
        "actual_df[\"variante\"] = actual_df[\"variante\"].astype(str)\n",
        "actual_stops = set(actual_df[\"stop_id\"])\n",
        "\n",
        "for filename in glob(\"/content/main/ordered_lines/*.csv\"):\n",
        "  # filename = '/content/main/ordered_lines/Line71_ordered.csv'\n",
        "  cur_lineID = str(int(filename.split('/')[-1].split('_')[0][4:]))\n",
        "  df = pd.read_csv(filename)\n",
        "  df[\"lineID\"] = df[\"lineID\"].astype(str)\n",
        "  df[\"directionID\"] = df[\"directionID\"].astype(str)\n",
        "  df[\"pointID\"] = df[\"pointID\"].astype(str).apply(lambda x: x.strip().split(\" \")[0])\n",
        "  print('Line ', cur_lineID)\n",
        "  n_faulty = df.loc[df['succession']==999999].shape[0]\n",
        "  n_all = df.shape[0]\n",
        "  print(f'before {n_faulty} ({round((n_faulty/n_all)*100, 2)}%)')\n",
        "\n",
        "  for idx, faulty_row in df.loc[df['succession']==999999].iterrows():\n",
        "    try:\n",
        "      lineID = faulty_row.loc['lineID']\n",
        "      pointID = faulty_row.loc['pointID']\n",
        "      pointID_desc = actual_df.loc[actual_df['stop_id'] == pointID].iloc[0]['descr_fr']\n",
        "      directionID = faulty_row.loc['directionID']\n",
        "      directionID_desc = actual_df.loc[actual_df['stop_id']==directionID].iloc[0]['descr_fr']\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    # might be the same bus stop but for a different line\n",
        "    # that's why, if exists, get another pointID that has the same description, lineID and terminus\n",
        "    matched_stops = actual_df.loc[(actual_df['descr_fr']==pointID_desc) & (actual_df['numero_lig'] == lineID) & (actual_df['terminus'] == directionID_desc)]\n",
        "\n",
        "    if not matched_stops.empty:\n",
        "      # if such a bus stop is found\n",
        "      if matched_stops.shape[0] != 1:\n",
        "        # print('Too many matches!')\n",
        "        continue\n",
        "      new_succession = int(matched_stops.iloc[0]['succession'])\n",
        "      df.at[idx, 'succession'] = new_succession\n",
        "      continue\n",
        "    \n",
        "    # cur_directionId might be stop before the actual terminal\n",
        "    # in that case check that there is another pointID that has the same description, lineID and pointID as cur_directionID\n",
        "    # if pointID is the same, then it's the going with the same route\n",
        "    cur_dirID_info = actual_df.loc[(actual_df['descr_fr']==directionID_desc) & (actual_df['numero_lig'] == lineID) & (actual_df['stop_id'] == directionID)]\n",
        "    if not cur_dirID_info.empty:\n",
        "      if cur_dirID_info.shape[0] != 1:\n",
        "        # print('Too many matches for case 2')\n",
        "        continue\n",
        "\n",
        "      # the actual terminal stop\n",
        "      main_dirID_desc = cur_dirID_info.iloc[0]['terminus']\n",
        "\n",
        "      # find the target bus stop's succession with the actual terminal stop\n",
        "      correct_stop_info = actual_df.loc[(actual_df['descr_fr']==pointID_desc) & (actual_df['terminus'] == main_dirID_desc) & (actual_df['numero_lig']==lineID)]\n",
        "      if correct_stop_info.shape[0] != 1:\n",
        "        # print('Too many or not enough matches for case 2 correct info')\n",
        "        continue\n",
        "      \n",
        "      new_succession = int(correct_stop_info.iloc[0]['succession'])\n",
        "\n",
        "      # and confirm that cur_directionID is greater in succession than the current pointID\n",
        "      if int(cur_dirID_info.iloc[0]['succession']) < new_succession:\n",
        "        # print('Terminal Stop Succession is smaller than earlier stop')\n",
        "        continue\n",
        "      \n",
        "      df.at[idx, 'succession'] = new_succession\n",
        "      continue\n",
        "  n_faulty = df.loc[df['succession']==999999].shape[0]\n",
        "  n_all = df.shape[0]\n",
        "  print(f'after {n_faulty} ({round((n_faulty/n_all)*100, 2)}%)')\n",
        "  df.sort_values([\"directionID\", \"time\",  \"succession\",], ascending=[True, True, True]).to_csv(f\"/content/main/ordered_lines/Line{cur_lineID}_ordered.csv\")"
      ],
      "metadata": {
        "id": "oXw7Q7KgTaSu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "66130ebb-c18d-44d4-d28b-fe3679cccbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line  12\n",
            "before 5496 (2.3%)\n",
            "after 5496 (2.3%)\n",
            "Line  13\n",
            "before 12387 (5.35%)\n",
            "after 12387 (5.35%)\n",
            "Line  14\n",
            "before 38854 (14.26%)\n",
            "after 26554 (9.74%)\n",
            "Line  17\n",
            "before 968 (1.03%)\n",
            "after 324 (0.34%)\n",
            "Line  19\n",
            "before 221734 (59.27%)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-214-363c943ad62a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;31m# find the target bus stop's succession with the actual terminal stop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0mcorrect_stop_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'descr_fr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpointID_desc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'terminus'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmain_dirID_desc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'numero_lig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlineID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcorrect_stop_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# print('Too many or not enough matches for case 2 correct info')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5502\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in glob(\"/content/main/ordered_lines/*.csv\"):\n",
        "  # filename = '/content/main/ordered_lines/Line71_ordered.csv'\n",
        "  cur_lineID = str(int(filename.split('/')[-1].split('_')[0][4:]))\n",
        "  df = pd.read_csv(filename)\n",
        "  df[\"lineID\"] = df[\"lineID\"].astype(str)\n",
        "  df[\"directionID\"] = df[\"directionID\"].astype(str)\n",
        "  df[\"pointID\"] = df[\"pointID\"].astype(str).apply(lambda x: x.strip().split(\" \")[0])\n",
        "  print('Line ', cur_lineID)\n",
        "  n_faulty = df.loc[df['succession']==999999].shape[0]\n",
        "  n_all = df.shape[0]\n",
        "  print(f'before {n_faulty} ({round((n_faulty/n_all)*100, 2)}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X0i2ZgVGYhJ",
        "outputId": "7bf7ebcf-189b-4d7a-cc66-d6b308f91db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Line  12\n",
            "before 5496 (2.3%)\n",
            "Line  13\n",
            "before 12387 (5.35%)\n",
            "Line  14\n",
            "before 26554 (9.74%)\n",
            "Line  17\n",
            "before 324 (0.34%)\n",
            "Line  19\n",
            "before 221734 (59.27%)\n",
            "Line  1\n",
            "before 177016 (57.95%)\n",
            "Line  20\n",
            "before 26897 (11.19%)\n",
            "Line  21\n",
            "before 13809 (7.04%)\n",
            "Line  25\n",
            "before 387235 (100.0%)\n",
            "Line  27\n",
            "before 44504 (20.03%)\n",
            "Line  28\n",
            "before 13510 (7.16%)\n",
            "Line  29\n",
            "before 51606 (14.64%)\n",
            "Line  2\n",
            "before 25443 (11.83%)\n",
            "Line  33\n",
            "before 704 (1.01%)\n",
            "Line  34\n",
            "before 93732 (34.52%)\n",
            "Line  36\n",
            "before 73993 (30.42%)\n",
            "Line  37\n",
            "before 37662 (22.98%)\n",
            "Line  38\n",
            "before 86436 (24.93%)\n",
            "Line  39\n",
            "before 140251 (66.38%)\n",
            "Line  3\n",
            "before 258804 (67.48%)\n",
            "Line  41\n",
            "before 34311 (14.65%)\n",
            "Line  42\n",
            "before 10022 (8.02%)\n",
            "Line  43\n",
            "before 40637 (19.76%)\n",
            "Line  44\n",
            "before 88253 (47.22%)\n",
            "Line  45\n",
            "before 41233 (18.39%)\n",
            "Line  46\n",
            "before 72315 (19.33%)\n",
            "Line  47\n",
            "before 58683 (29.06%)\n",
            "Line  48\n",
            "before 84633 (24.62%)\n",
            "Line  49\n",
            "before 21177 (6.49%)\n",
            "Line  4\n",
            "before 231078 (81.67%)\n",
            "Line  50\n",
            "before 4577 (2.55%)\n",
            "Line  51\n",
            "before 110492 (22.09%)\n",
            "Line  53\n",
            "before 1473 (0.4%)\n",
            "Line  54\n",
            "before 32796 (11.86%)\n",
            "Line  55\n",
            "before 294203 (99.49%)\n",
            "Line  56\n",
            "before 5473 (2.3%)\n",
            "Line  57\n",
            "before 3143 (2.92%)\n",
            "Line  58\n",
            "before 4002 (1.86%)\n",
            "Line  59\n",
            "before 185267 (62.48%)\n",
            "Line  5\n",
            "before 150676 (37.12%)\n",
            "Line  60\n",
            "before 8175 (2.94%)\n",
            "Line  61\n",
            "before 62187 (35.66%)\n",
            "Line  62\n",
            "before 84560 (69.9%)\n",
            "Line  63\n",
            "before 12758 (5.52%)\n",
            "Line  64\n",
            "before 143113 (55.09%)\n",
            "Line  65\n",
            "before 256272 (60.47%)\n",
            "Line  66\n",
            "before 190600 (71.47%)\n",
            "Line  69\n",
            "before 18085 (54.67%)\n",
            "Line  6\n",
            "before 44829 (13.46%)\n",
            "Line  70\n",
            "before 29552 (25.74%)\n",
            "Line  71\n",
            "before 3314 (0.76%)\n",
            "Line  72\n",
            "before 571 (1.35%)\n",
            "Line  74\n",
            "before 30540 (14.42%)\n",
            "Line  75\n",
            "before 1851 (1.64%)\n",
            "Line  76\n",
            "before 26687 (42.28%)\n",
            "Line  77\n",
            "before 0 (0.0%)\n",
            "Line  78\n",
            "before 52326 (48.54%)\n",
            "Line  79\n",
            "before 20457 (11.16%)\n",
            "Line  7\n",
            "before 167607 (31.68%)\n",
            "Line  80\n",
            "before 29382 (7.52%)\n",
            "Line  81\n",
            "before 303830 (60.16%)\n",
            "Line  82\n",
            "before 191702 (37.16%)\n",
            "Line  83\n",
            "before 82953 (28.36%)\n",
            "Line  86\n",
            "before 36829 (14.69%)\n",
            "Line  87\n",
            "before 23581 (7.64%)\n",
            "Line  88\n",
            "before 3280 (1.2%)\n",
            "Line  89\n",
            "before 74822 (32.01%)\n",
            "Line  8\n",
            "before 27175 (7.03%)\n",
            "Line  92\n",
            "before 263808 (54.24%)\n",
            "Line  93\n",
            "before 199819 (49.59%)\n",
            "Line  95\n",
            "before 360452 (67.82%)\n",
            "Line  97\n",
            "before 40299 (14.56%)\n",
            "Line  98\n",
            "before 47648 (48.25%)\n",
            "Line  9\n",
            "before 85475 (65.11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XkZPaZ_bAHtt",
        "outputId": "3a53456b-6379-4fba-b72c-ebaa35493b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0           time lineID directionID  distancefromPoint  \\\n",
              "0            34064  1631018950001     19         471                  0   \n",
              "1            34078  1631018982872     19         471                  0   \n",
              "2            34093  1631019015919     19         471                  0   \n",
              "3            34107  1631019048512     19         471                  0   \n",
              "4            34121  1631019079131     19         471                  0   \n",
              "...            ...            ...    ...         ...                ...   \n",
              "374095      353570  1632179202844     19        5700                  0   \n",
              "374096      353571  1632179234281     19        5700                  0   \n",
              "374097      353572  1632179266232     19        5700                  0   \n",
              "374098      353574  1632179297260     19        5700                  0   \n",
              "374099      353576  1632179329720     19        5700                  0   \n",
              "\n",
              "       pointID  succession  \n",
              "0         5103      999999  \n",
              "1         5103      999999  \n",
              "2         5103      999999  \n",
              "3         5103      999999  \n",
              "4         5103      999999  \n",
              "...        ...         ...  \n",
              "374095    5700      999999  \n",
              "374096    5700      999999  \n",
              "374097    5700      999999  \n",
              "374098    5700      999999  \n",
              "374099    5700      999999  \n",
              "\n",
              "[374100 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0b5833d-7252-4325-96a3-fd64e9e3f021\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>time</th>\n",
              "      <th>lineID</th>\n",
              "      <th>directionID</th>\n",
              "      <th>distancefromPoint</th>\n",
              "      <th>pointID</th>\n",
              "      <th>succession</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34064</td>\n",
              "      <td>1631018950001</td>\n",
              "      <td>19</td>\n",
              "      <td>471</td>\n",
              "      <td>0</td>\n",
              "      <td>5103</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34078</td>\n",
              "      <td>1631018982872</td>\n",
              "      <td>19</td>\n",
              "      <td>471</td>\n",
              "      <td>0</td>\n",
              "      <td>5103</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34093</td>\n",
              "      <td>1631019015919</td>\n",
              "      <td>19</td>\n",
              "      <td>471</td>\n",
              "      <td>0</td>\n",
              "      <td>5103</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34107</td>\n",
              "      <td>1631019048512</td>\n",
              "      <td>19</td>\n",
              "      <td>471</td>\n",
              "      <td>0</td>\n",
              "      <td>5103</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34121</td>\n",
              "      <td>1631019079131</td>\n",
              "      <td>19</td>\n",
              "      <td>471</td>\n",
              "      <td>0</td>\n",
              "      <td>5103</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374095</th>\n",
              "      <td>353570</td>\n",
              "      <td>1632179202844</td>\n",
              "      <td>19</td>\n",
              "      <td>5700</td>\n",
              "      <td>0</td>\n",
              "      <td>5700</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374096</th>\n",
              "      <td>353571</td>\n",
              "      <td>1632179234281</td>\n",
              "      <td>19</td>\n",
              "      <td>5700</td>\n",
              "      <td>0</td>\n",
              "      <td>5700</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374097</th>\n",
              "      <td>353572</td>\n",
              "      <td>1632179266232</td>\n",
              "      <td>19</td>\n",
              "      <td>5700</td>\n",
              "      <td>0</td>\n",
              "      <td>5700</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374098</th>\n",
              "      <td>353574</td>\n",
              "      <td>1632179297260</td>\n",
              "      <td>19</td>\n",
              "      <td>5700</td>\n",
              "      <td>0</td>\n",
              "      <td>5700</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374099</th>\n",
              "      <td>353576</td>\n",
              "      <td>1632179329720</td>\n",
              "      <td>19</td>\n",
              "      <td>5700</td>\n",
              "      <td>0</td>\n",
              "      <td>5700</td>\n",
              "      <td>999999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>374100 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0b5833d-7252-4325-96a3-fd64e9e3f021')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0b5833d-7252-4325-96a3-fd64e9e3f021 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0b5833d-7252-4325-96a3-fd64e9e3f021');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "faulty_row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCB0eZsD5NKh",
        "outputId": "76e3d42b-ac56-4e9a-8aff-dc2acc4c101e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                  131027\n",
              "Unnamed: 0.1                 92676\n",
              "time                 1631415236099\n",
              "lineID                          12\n",
              "directionID                   6465\n",
              "distancefromPoint               84\n",
              "pointID                       1317\n",
              "succession                  999999\n",
              "Name: 131027, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual_df.loc[actual_df['stop_id'] == pointID]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "cD72pGGI5coz",
        "outputId": "a825a2a6-9cce-47db-e06b-648ab18a3b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [gid, code_ligne, variante, succession, stop_id, descr_fr, descr_nl, alpha_fr, alpha_nl, coord_x, coord_y, mode, numero_lig, terminus, geom]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-607930c9-d9cb-43cc-b2f4-f2653ce2da8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gid</th>\n",
              "      <th>code_ligne</th>\n",
              "      <th>variante</th>\n",
              "      <th>succession</th>\n",
              "      <th>stop_id</th>\n",
              "      <th>descr_fr</th>\n",
              "      <th>descr_nl</th>\n",
              "      <th>alpha_fr</th>\n",
              "      <th>alpha_nl</th>\n",
              "      <th>coord_x</th>\n",
              "      <th>coord_y</th>\n",
              "      <th>mode</th>\n",
              "      <th>numero_lig</th>\n",
              "      <th>terminus</th>\n",
              "      <th>geom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-607930c9-d9cb-43cc-b2f4-f2653ce2da8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-607930c9-d9cb-43cc-b2f4-f2653ce2da8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-607930c9-d9cb-43cc-b2f4-f2653ce2da8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Normalize the distance\n",
        " The algorithm will work as follow:\n",
        " 1. We will change the distance for non-zero distance point by subtracting the time with how much time passed since the bus in the 0 distance of the point\n",
        " 2. We will use the bus/tram average speed to calculate the distance passed\n",
        "'''\n",
        "line_df = pd.read_csv(\"/content/main/ordered_lines/Line71_ordered.csv\")\n",
        "\n",
        "# Remove outlier\n",
        "line_df = line_df[line_df[\"succession\"] != 999999]\n",
        "\n",
        "columns = [\"time\", \"lineID\", \"directionID\", \"distancefromPoint\", \"pointID\", \"succession\"]\n",
        "\n",
        "size = line_df.shape[0]\n",
        "delimiters = np.array([\"_\" for _ in range(size)])\n",
        "\n",
        "line_infos = None\n",
        "for idx, column in enumerate(columns):\n",
        "    line_df[column] = line_df[column].astype(str)\n",
        "    if line_infos is None:\n",
        "        line_infos = line_df[column].to_numpy() + delimiters\n",
        "    elif line_infos is not None and idx < len(columns)-1:\n",
        "        line_infos += line_df[column].to_numpy() + delimiters\n",
        "    else:\n",
        "        line_infos += line_df[column].to_numpy()\n",
        "\n",
        "        \n",
        "# Array for building new dataset\n",
        "converted_timestamp = []\n",
        "converted_distances = []\n",
        "direction_ids = []\n",
        "point_ids = []\n",
        "line_ids = []\n",
        "orders = []\n",
        "original_timestamp = []\n",
        "original_distances = []\n",
        "\n",
        "for line_info in line_infos:\n",
        "    line = line_info.split(\"_\")\n",
        "\n",
        "    # Unpack information\n",
        "    timestamp = int(line[0])\n",
        "    line_id = line[1]\n",
        "    direction_id = line[2]\n",
        "    distance = decimal.Decimal(line[3])\n",
        "    point_id = line[4]\n",
        "    order = int(line[5])\n",
        "    \n",
        "    # Ignore stopping bus\n",
        "    if int(distance) == 0:\n",
        "        line_ids.append(line_id)\n",
        "        direction_ids.append(direction_id)\n",
        "        point_ids.append(point_id)\n",
        "        orders.append(order)\n",
        "        \n",
        "        original_timestamp.append(epoch_ms_to_datetime(timestamp))\n",
        "        converted_timestamp.append(epoch_ms_to_datetime(timestamp))\n",
        "        original_distances.append(distance)  \n",
        "        converted_distances.append(distance)\n",
        "        continue\n",
        "    \n",
        "    # Calculate -5 meters and +5 meters from stop\n",
        "    # The interpolation threshold is chosen by using heuristic method\n",
        "    # We will consider bus position -5 metres or +5 metres from stop is considered as stopping    \n",
        "    # Normalized the timestamp\n",
        "    timestamp_plus = timestamp - (int(((distance+STOP_DISTANCE_THRESHOLD) / AVERAGE_SPEED)*TO_MS))\n",
        "    timestamp_min = timestamp - (int(((distance-STOP_DISTANCE_THRESHOLD) / AVERAGE_SPEED)*TO_MS))\n",
        "    \n",
        "    timestamps = [timestamp_min, timestamp_plus]\n",
        "    time_passed = [(int((distance-STOP_DISTANCE_THRESHOLD) / AVERAGE_SPEED)), (int((distance+STOP_DISTANCE_THRESHOLD) / AVERAGE_SPEED))] \n",
        "    \n",
        "    # Add the interpolation data\n",
        "    for idx in range(len(timestamps)):\n",
        "        line_ids.append(line_id)\n",
        "        direction_ids.append(direction_id)\n",
        "        point_ids.append(point_id)\n",
        "        orders.append(order)\n",
        "        \n",
        "        original_timestamp.append(epoch_ms_to_datetime(timestamp))\n",
        "        converted_timestamp.append(epoch_ms_to_datetime(timestamps[idx]))\n",
        "        \n",
        "        original_distances.append(distance)   \n",
        "        converted_distances.append(distance - (AVERAGE_SPEED*time_passed[idx]))\n",
        "\n",
        "columns = {\n",
        "            \"line_id\": np.array(line_ids), \n",
        "           \"direction_id\": np.array(direction_ids),\n",
        "           \"point_id\": np.array(point_ids), \n",
        "           \"order\": np.array(orders), \n",
        "           \"original_timestamp\": np.array(original_timestamp), \n",
        "           \"converted_timestamp\": np.array(converted_timestamp), \n",
        "           \"original_distance\": np.array(original_distances), \n",
        "           \"converted_distance\": np.array(converted_distances)\n",
        "          }\n",
        "\n",
        "\n",
        "converted_df = pd.DataFrame(columns)\n",
        "converted_df.sort_values([\"direction_id\", \"order\", \"converted_timestamp\"], ascending=[True, True, True]).to_csv(\"/content/main/normalized_lines/Line71_normalized.csv\")"
      ],
      "metadata": {
        "id": "85KgMY27UR3A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array, linspace, sort\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from matplotlib.pyplot import plot\n",
        "from scipy.signal import argrelextrema\n",
        "from jenkspy import JenksNaturalBreaks\n",
        "from dbscan1d.core import DBSCAN1D\n",
        "\n",
        "import ckwrap\n",
        "\n",
        "\n",
        "normalized_df = pd.read_csv(\"/content/main/normalized_lines/Line71_normalized.csv\")\n",
        "normalized_df = normalized_df[(normalized_df[\"order\"].astype(int) == 9)  & (normalized_df[\"direction_id\"] == 2596 )]\n",
        "normalized_df[\"converted_timestamp\"] = normalized_df[\"converted_timestamp\"].apply(lambda x: (pd.Timestamp(x)))\n",
        "\n",
        "arrival_time = normalized_df['converted_timestamp'].apply(lambda x: (x - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')).to_numpy()\n",
        "\n",
        "number_of_trips = pd.read_csv(\"/content/main/schedule/schedules/schedule_71_2596.csv\")\n",
        "n = len(number_of_trips[\"3562B\"])\n",
        "\n",
        "\n",
        "'''\n",
        "    Jenkins binning algorithm\n",
        "'''\n",
        "jnb = JenksNaturalBreaks(n)\n",
        "jnb.fit(arrival_time)\n",
        "\n",
        "\n",
        "'''\n",
        " Kernel Density estimation method\n",
        "'''\n",
        "first = arrival_time[0]\n",
        "a = np.array([(x-first) for x in arrival_time])\n",
        "\n",
        "# a = np.array([1,1,1,2,3,4,10,12,16,40,45])\n",
        "a = a.reshape(-1, 1)\n",
        "\n",
        "kde = KernelDensity(kernel='gaussian', bandwidth=0.01).fit(a)\n",
        "\n",
        "s = linspace(a[0],a[-1]+2000)\n",
        "e = kde.score_samples(s.reshape(-1,1))\n",
        "mi, ma = argrelextrema(e, np.less)[0], argrelextrema(e, np.greater)[0]\n",
        "\n",
        "clusters = []\n",
        "\n",
        "clusters.append(a[a < s[mi][0]])  # most left cluster\n",
        "\n",
        "# print all middle cluster\n",
        "for i_cluster in range(len(mi)-1):\n",
        "    clusters.append(a[(a >= s[mi][i_cluster]) * (a <= s[mi][i_cluster+1])])\n",
        "\n",
        "clusters.append(a[a >= s[mi][-1]])  # print most right cluster\n",
        "\n",
        "'''\n",
        "    dbsscan approach\n",
        "    epsilon is 35 seconds \n",
        "'''\n",
        "dbs = DBSCAN1D(eps=35, min_samples=1)\n",
        "labels = dbs.fit_predict(arrival_time)\n",
        "\n",
        "'''\n",
        "    kmeans 1d\n",
        "'''\n",
        "first = arrival_time[0]\n",
        "data = np.array([(x-first) for x in arrival_time])\n",
        "result = ckwrap.ckmeans(data, n)"
      ],
      "metadata": {
        "id": "oFlCv6duUw9f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df[\"dbscan\"] = np.array(dbs.labels_)\n",
        "normalized_df[\"kmeans\"] = np.array(result.labels)\n",
        "normalized_df[\"jenkins\"] = np.array(jnb.labels_)\n",
        "\n",
        "kde_labels = []\n",
        "for idx, cluster in enumerate(clusters):\n",
        "    for x in cluster:\n",
        "        kde_labels.append(idx)\n",
        "        \n",
        "normalized_df[\"KDE\"] = np.array(kde_labels)\n",
        "\n",
        "normalized_df.to_csv(\"/content/main/arrival_time/sample_cluster.csv\")"
      ],
      "metadata": {
        "id": "_QevZcxQJqu1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V97LT2U5JrdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}