{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "119f1110-029d-4960-b230-49751ac4e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "import decimal\n",
    "\n",
    "from glob import glob\n",
    "from google.cloud import storage\n",
    "\n",
    "client = storage.Client()\n",
    "bucket = client.get_bucket('datamining-ulb')\n",
    "\n",
    "decimal.getcontext().prec = 3\n",
    "TO_MS = decimal.Decimal(\"1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6af3c5d9-3540-41ed-9da5-b854516f688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Helper functions\n",
    "'''\n",
    "\n",
    "def epoch_ms_to_datetime(epoch_ms: int) -> datetime.datetime:\n",
    "    return datetime.datetime.fromtimestamp(epoch_ms / int(TO_MS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bbef205-5d9b-49e8-8cca-b01703bec506",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(bucket\u001b[38;5;241m.\u001b[39mlist_blobs(prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLines_vehiclePositions/Line\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m---> 59\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;241m.\u001b[39mbucket\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;129;01mor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[1;32m     62\u001b[0m           \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "# Extract actual stops\n",
    "actual_df = pd.read_csv(f\"gs://{bucket.name}/data/actual_stops.csv\")\n",
    "size = actual_df.shape[0]\n",
    "actual_df[\"stop_id\"] = [re.sub(\"\\D\", \"\", x.strip()) for x in actual_df[\"stop_id\"]]\n",
    "\n",
    "actual_df[\"succession\"] = actual_df[\"succession\"].astype(str)\n",
    "actual_df[\"numero_lig\"] = actual_df[\"numero_lig\"].astype(str)\n",
    "actual_df[\"variante\"] = actual_df[\"variante\"].astype(str)\n",
    "\n",
    "actual_stops = set(actual_df[\"stop_id\"])\n",
    "\n",
    "# Extract Line stop sequence\n",
    "extracted_lines = {}\n",
    "\n",
    "delimiters = np.array([\"_\" for _ in range(size)])\n",
    "stops_info = (actual_df[\"numero_lig\"].to_numpy() + delimiters +  actual_df[\"succession\"].to_numpy() + delimiters + actual_df[\"variante\"].to_numpy() + delimiters + actual_df[\"stop_id\"].to_numpy()).tolist()\n",
    "\n",
    "prev_succession = -999999\n",
    "direction = \"\"\n",
    "for stops in stops_info[::-1]:\n",
    "    info = stops.split(\"_\")\n",
    "    if int(prev_succession) < int(info[1]):\n",
    "        direction = info[3]\n",
    "    \n",
    "    data = extracted_lines.setdefault(info[0], {})\n",
    "    \n",
    "    succession_info = data.setdefault(info[3], {})\n",
    "    succession_info[direction] = info[1]\n",
    "    \n",
    "    data[info[3]] = succession_info\n",
    "    extracted_lines[info[0]] = data\n",
    "    \n",
    "    line_direction = data.setdefault(\"direction\", {})\n",
    "    visited_stops = line_direction.setdefault(direction, set())\n",
    "    visited_stops.add(info[3])\n",
    "    \n",
    "    line_direction[direction] = visited_stops\n",
    "    data[\"direction\"] = line_direction\n",
    "    \n",
    "    prev_succession = info[1]\n",
    "\n",
    "'''\n",
    "Pair stops with the succession line, \n",
    " 1. if there's multiple sucession line check whether direction is the same\n",
    " 2. If not, try to find direction id in the direction stops\n",
    " 3. otherwise set sucession to 99999\n",
    "'''\n",
    "\n",
    "# Dont iterate over complete data\n",
    "names = set()\n",
    "for file in list(bucket.list_blobs(prefix='ordered_lines/Line')):\n",
    "    file_path=f\"gs://{file.bucket.name}/{file.name}\"\n",
    "    \n",
    "    name = file_path.strip().split(\"/\")[4].split(\"_\")[0]\n",
    "    names.add(name)\n",
    "\n",
    "lines = []\n",
    "for file_path in list(bucket.list_blobs(prefix='Lines_vehiclePositions/Line')):\n",
    "    file = f\"gs://{file_path.bucket.name}/{file_path.name}\"\n",
    "    \n",
    "    if \"null\" in file or file in names:\n",
    "          continue\n",
    "            \n",
    "    df = pd.read_csv(file);\n",
    "    \n",
    "    df[\"lineID\"] = df[\"lineID\"].astype(str)\n",
    "    df[\"directionID\"] = df[\"directionID\"].astype(str)\n",
    "    df[\"pointID\"] = df[\"pointID\"].astype(str)\n",
    "    \n",
    "    delimiters = np.array([\"_\" for _ in range(df.shape[0])])\n",
    "    stops_infos = (df[\"lineID\"].to_numpy() + delimiters + df[\"directionID\"].to_numpy() + delimiters + df[\"pointID\"].to_numpy() + delimiters + df.index.astype(str).values).tolist()\n",
    "    \n",
    "    succession_arr = []\n",
    "    for stop in stops_infos:\n",
    "        info = stop.split(\"_\")\n",
    "        data = extracted_lines[info[0]]\n",
    "        \n",
    "        succession = 999999\n",
    "        if info[2] not in data:\n",
    "            succession_arr.append(succession)\n",
    "            continue\n",
    "        \n",
    "        succession_info = data[info[2]]\n",
    "        if info[1] not in succession_info:\n",
    "            succession_arr.append(succession)\n",
    "            continue\n",
    "        \n",
    "        succession = succession_info[info[1]]\n",
    "        succession_arr.append(succession)\n",
    "    \n",
    "    df[\"succession\"] = np.array(succession_arr)\n",
    "    \n",
    "    df[\"lineID\"] = df[\"lineID\"].astype(int)\n",
    "    df[\"directionID\"] = df[\"directionID\"].astype(int)\n",
    "    df[\"pointID\"] = df[\"pointID\"].astype(int)\n",
    "    df[\"succession\"] = df[\"succession\"].astype(int)\n",
    "    \n",
    "    df.sort_values([\"directionID\", \"time\",  \"succession\",], ascending=[True, True, True]).to_csv(f\"gs://{bucket.name}/ordered_lines/{name}_ordered.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42260476-fdf2-4778-8df8-724263565230",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normalize the distance\n",
    " The algorithm will work as follow:\n",
    " 1. We will change the distance for non-zero distance point by subtracting the time with how much time passed since the bus in the 0 distance of the point\n",
    " 2. We will use the bus/tram average speed to calculate the distance passed\n",
    "'''\n",
    "\n",
    "AVERAGE_SPEED = decimal.Decimal(\"4.667\") # in metre/second\n",
    "\n",
    "\n",
    "line_df = pd.read_csv(f\"gs://{bucket.name}/ordered_lines/Line71_ordered.csv\")\n",
    "\n",
    "# Remove outlier\n",
    "line_df = line_df[line_df[\"succession\"] != 999999]\n",
    "\n",
    "columns = [\"time\", \"lineID\", \"directionID\", \"distancefromPoint\", \"pointID\", \"succession\"]\n",
    "\n",
    "size = line_df.shape[0]\n",
    "delimiters = np.array([\"_\" for _ in range(size)])\n",
    "\n",
    "line_infos = None\n",
    "for idx, column in enumerate(columns):\n",
    "    line_df[column] = line_df[column].astype(str)\n",
    "    if line_infos is None:\n",
    "        line_infos = line_df[column].to_numpy() + delimiters\n",
    "    elif line_infos is not None and idx < len(columns)-1:\n",
    "        line_infos += line_df[column].to_numpy() + delimiters\n",
    "    else:\n",
    "        line_infos += line_df[column].to_numpy()\n",
    "\n",
    "normalized_timestamp = []\n",
    "normalized_distance = []\n",
    "for line_info in line_infos:\n",
    "    line = line_info.split(\"_\")\n",
    "\n",
    "    # Define var\n",
    "    timestamp = int(line[0])\n",
    "    distance = decimal.Decimal(line[3])\n",
    "    \n",
    "    if distance == 0:\n",
    "        normalized_timestamp.append(epoch_ms_to_datetime(timestamp))\n",
    "        normalized_distance.append(distance)\n",
    "        continue\n",
    "        \n",
    "    # Normalized the timestamp\n",
    "    time_passed = distance / AVERAGE_SPEED\n",
    "    timestamp -= (int(time_passed*TO_MS))\n",
    "    \n",
    "    normalized_timestamp.append(epoch_ms_to_datetime(timestamp))\n",
    "    normalized_distance.append(math.floor(abs(distance - (AVERAGE_SPEED*time_passed))))\n",
    "\n",
    "\n",
    "line_df[\"normalized_timestamp\"] = np.array(normalized_timestamp)\n",
    "line_df[\"normalized_distance\"] = np.array(normalized_distance)\n",
    "\n",
    "for idx, column in enumerate(columns):\n",
    "    line_df[column] = line_df[column].astype(int)\n",
    "\n",
    "\n",
    "line_df[\"time\"] = line_df[\"time\"].apply(lambda x: epoch_ms_to_datetime(x))\n",
    "line_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "line_df.sort_values([\"directionID\", \"succession\", \"normalized_timestamp\"], ascending=[True, True, True]).to_csv(f\"gs://{bucket.name}/normalized_lines/Line71_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd337f97-a91f-4d0c-b3da-98fc72d187d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
